---
title: "ML Domain Comparison"
format: pdf
editor: source
---

```{r}
library(tidyverse)
library(kableExtra)
library(readr)
library(plotly)
```

# Global params

```{r include = FALSE}
imagepath = "plots"
tablepath = "tables"
mltrackeddatapath = "tracked_data"
trackeddatapath = "../src/tracked_data"
fileprefix = "ML_Domain_Comparison_"

# update_geom_defaults("text", list(size = 20))
base_size <- 18
theme_set(theme_minimal(base_size = base_size))
theme_pres <- function(base_size){
  theme_get() %+replace%
    theme(axis.ticks = element_line(colour = "grey70", linewidth = rel(0.5)),
          panel.grid = element_blank(),
          panel.grid.major.y = element_line(colour = 'grey90', linewidth = rel(0.5)),
          # panel.border = element_rect(fill = NA, colour = "grey30", linewidth = rel(0.8)),
          strip.text = element_text(size=1.03*base_size),
          legend.text = element_text(size=1.1*base_size))
}
pres_palette <- c("#482677FF", "#1D7C5A", "#A64902", "#e7298a", "#0072B2", "#F0E442", "#D55E50", "#CC79A7")
```

```{r}
filenames_df <- tribble(
  ~target, ~transform,   ~models,        ~set, ~split_feature1,                ~splits1, ~split_feature2,         ~splits2,     ~csv_file,   ~csv_file_within,     ~train_split,
     # 'fc',           "",        "", 'djdrank10',   'relseaspeed', paste0("quart", c(1,4)),       'draught', c('high', 'low'), 'test_target',     'train_target',           NA,
     # 'fe',     'linear',       "", 'djdrank10',   'relseaspeed', paste0("quart", c(1,4)),       'draught', c('high', 'low'),     'test_fc',         'train_fc',           NA,
     # 'fc',           "",       "", 'djdrank10',   'relseaspeed',    paste0("quart", 1:4),              NA,               NA,     'test_fc',     'train_target',           NA,
     # 'fe',     'linear',       "", 'djdrank10',   'relseaspeed',    paste0("quart", 1:4),              NA,               NA,     'test_fc',         'train_fc',           NA,
     # 'fc',           '',       "",      'oecd',   'relseaspeed',    paste0("quart", 1:4),              NA,               NA,     'test_fc',     'train_target',           NA,
     # 'fe',     'linear',       "",      'oecd',   'relseaspeed',    paste0("quart", 1:4),              NA,               NA,     'test_fc',         'train_fc',           NA,
     # 'fc',           '',       "",  'djdrank4',   'relseaspeed',    paste0("quart", 1:4),              NA,               NA,     'test_fc',     'train_target',           NA,
     # 'fc',           '',       "", 'speeddist',   'relseaspeed',    paste0("quart", 1:4),              NA,               NA,     'test_fc',     'train_target',           NA,
     # 'fe',     'linear',       "",  'djdrank4',   'relseaspeed',    paste0("quart", 1:4),              NA,               NA,     'test_fc',         'train_fc',           NA,
     # 'fe',     'linear',       "", 'speeddist',   'relseaspeed',    paste0("quart", 1:4),              NA,               NA,     'test_fc',         'train_fc',           NA,
     # 'fc',           '',       "",      'work',   'relseaspeed',    paste0("quart", 1:4),              NA,               NA,     'test_fc',     'train_target',           NA,
     # 'fcnorm', 'linear', "struct",   'struct',   'relseaspeed',    paste0("quart", 1:4),              NA,               NA,     'test_fc',         'train_fc',              NA,
     'fcnorm', 'linear', "struct",   "struct",   "relseaspeed",                     "dec1",            NA,               NA,      'test_fc',         'train_fc',          "high",
     'fcnorm', 'linear', "struct",   "struct",   "relseaspeed",                    "dec10",            NA,               NA,      'test_fc',         'train_fc',           "low",
     'fc',     'linear', "struct",   "structfc", "relseaspeed",                     "dec1",            NA,               NA,  'test_target',     'train_target',          "high",
     'fc',     'linear', "struct",   "structfc", "relseaspeed",                    "dec10",            NA,               NA,  'test_target',     'train_target',           "low"
)

filenames_df <- filenames_df |> 
  unnest(splits1) |> 
  unnest(splits2) |> 
  mutate(
    testsplit1 = str_c("test", splits1, split_feature1),
    testsplit2 = str_c("test", splits2, split_feature2),
    filename_base = str_c(
      "ML",
      str_to_upper(target),
      str_c("F", set),
      str_c(
        coalesce(str_c(testsplit1, testsplit2), testsplit1),
        ifelse(transform == "", "", str_c("_", transform)),
        ifelse(models == "", "", str_c("_", models))
      ),
      sep = '_'
    ),
    split = coalesce(
      str_c(splits1, splits2, sep = ', '),
      splits1
    ),
    filename = str_c(
      filename_base,
      str_c(csv_file, '.csv'),
      sep = '_'
    ),
    filename_within = str_c(
      if_else(
        is.na(train_split),
        filename_base |> str_replace_all('test', 'train'),
        filename_base |> str_replace_all(split, train_split)
      ),
      str_c(csv_file_within, '.csv'),
      sep = '_'
    )
  )

filenames_df |> select(filename_base, split, filename, filename_within)
```

# Load out of domain data

```{r}
metric_table <- tibble()

for(i in 1:nrow(filenames_df)){
      row <- filenames_df[i, ]
      df <- read_csv(
        file.path(mltrackeddatapath, row$filename),
        show_col_types = FALSE,
        col_select = -params
      ) |> 
        pivot_longer(
          -c(model, class_name),
          names_to = "metric",
          values_to = "transfer_error") |> 
        bind_cols(row |> select(set, split, target, transform))
      metric_table <- bind_rows(metric_table, df)
}

metric_table <- metric_table |> 
  mutate(
    set = as_factor(str_c(set, target, sep = '_')),
    set = fct_recode(set,
      "FE Speed & Distance" = "speeddist_fe",
      "FE Calc Components" = "djdrank4_fe",
      "FE Work" = "work_fe",
      "FE OECD" = "oecd_fe",
      "FE Preferred" = "djdrank10_fe",
      "FC Speed & Distance" = "speeddist_fc",
      "FC Calc Components" = "djdrank4_fc",
      "FC Work" = "work_fc",
      "FC OECD" = "oecd_fc",
      "FC Preferred" = "djdrank10_fc",
      "FC Norm Structural" = "struct_fcnorm",
      "FC Structural" = "structfc_fc"
    ),
    set = fct_relevel(set,
      "FE Speed & Distance",
      "FE Calc Components",
      "FE Work",
      "FE OECD",
      "FE Preferred",
      "FC Speed & Distance",
      "FC Calc Components",
      "FC Work",
      "FC OECD",
      "FC Preferred",
      "FC Norm Structural",
      "FC Structural"
    )
  )
```

## ***Filter out bad models
```{r}
metric_table <- metric_table |> 
  filter(!(set == "FC Structural" & model == "linearstruct"))
```

# Functions

```{r}
best_stat_function <- function(stat, value){
  if (stat %in% c('mae', 'mape', 'rmse', 'mse', 'ate')) {
    min(value)
  } else if(stat %in% c('r2')) {
    max(value)
  } else {
    warning(paste(stat, "is an unknown statistic"))
    NA_real_
  }
}
```

```{r}
stat_plot_model <- function(
    metric_table,
    trans_error_stat = NULL,
    pred_error_stat = NULL,
    models = NULL,
    best_model_only = FALSE,
    ylims = c(NA, NA)
  ){
  
  metric_table <- metric_table |> 
    filter(metric == pred_error_stat)
  
  if (pred_error_stat == 'te') {
    metric_table <- metric_table |> 
      mutate(!!sym(trans_error_stat) := abs(!!sym(trans_error_stat)))
    pred_error_stat <- 'ate'
  }
  
  if (best_model_only) {
    metric_table <- metric_table |> 
      group_by(set, split) |> 
      filter(
        !!sym(trans_error_stat) == best_stat_function(
          pred_error_stat,
          !!sym(trans_error_stat)
        )
      ) |> 
      ungroup()
  if (!is.null(models)) {
    warning("models argument is ignored when best_model_only is TRUE")
  }
  models <- "all"
  }
  
  metric_table <- metric_table |> 
    filter(
      if (length(models) > 1 || models != "all") model %in% models else TRUE
    )
  
  group_means <- if (best_model_only) {
    metric_table |>
      group_by(set)
  } else {
    metric_table |> 
      group_by(model, set)
  }
  
  group_means <- group_means |> 
    summarise(mean = mean(!!sym(trans_error_stat)), .groups = "drop")
  
  stat_plot <- metric_table |> 
    ggplot(aes(x = split, y = !!sym(trans_error_stat), fill = set)) +
    geom_col(position = 'dodge') +
    geom_hline(aes(yintercept = mean, color = set),
               linetype = 'dashed',
               data = group_means) +
    scale_fill_manual(values = pres_palette) +
    scale_color_manual(values = pres_palette) +
    theme_pres(base_size) +
    labs(
      y = paste0(
        str_to_title(str_replace_all(trans_error_stat, "_", " ")),
        " (",
        str_to_upper(pred_error_stat),
        ")"
      ),
      x = 'Test split',
      fill = 'Feature set',
      color = 'Feature set'
    ) +
    coord_cartesian(ylim = ylims) +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  if (!best_model_only) {
    stat_plot <- stat_plot + facet_wrap(~model)
  }
  return(stat_plot)
}
```

# Transfer error

## Best model for each test domain

```{r}
stat_plot_model(
  metric_table,
  "transfer_error",
  "mape",
  # models = "all",
  best_model_only = TRUE
) |> 
  print()
```

```{r}
stat_plot_model(
  metric_table,
  "transfer_error",
  "mae",
  best_model_only = TRUE
) |> 
  print()
```

```{r}
stat_plot_model(
  metric_table,
  "transfer_error",
  "te",
  best_model_only = TRUE
) |> 
  print()
```

## Model-wise performance by test domain

### Calculation

```{r}
stat_plot_model(
  metric_table, 
  "transfer_error",
  "mape",
  "eng"
) |> 
  print()
```

```{r}
stat_plot_model(
  metric_table, 
  "transfer_error",
  "mae",
  "eng"
) |> 
  print()
```

### Gradient Boost

```{r}
if ("gb" %in% metric_table$model) {
  stat_plot_model(
    metric_table, 
    "transfer_error",
    "mae",
    "gb"
  ) |> 
    print()
}
```

### Ridge

```{r}
if ("ridge" %in% metric_table$model) {
  stat_plot_model(
    metric_table, 
    "transfer_error",
    "mape",
    "ridge"
  ) |> 
    print()
}
```

### All models

```{r}
stat_plot_model(
  metric_table, 
  "transfer_error",
  "mape",
  c("eng", "gb", "lasso", "linear", "rf", "ridge", "linearstruct")
) |> 
  print()
```

```{r}
stat_plot_model(
  metric_table, 
  "transfer_error",
  "mae",
  c("eng", "gb", "lasso", "linear", "rf", "ridge", "linearstruct")
) |> 
  print()
```

# Normalization Calculations

### Load within domain data

```{r}
metric_table_within <- tibble()

for(i in 1:nrow(filenames_df)){
      row <- filenames_df[i, ]
      df <- read_csv(
        file.path(mltrackeddatapath, row$filename_within),
        show_col_types = FALSE,
        col_select = -params
      ) |> 
        pivot_longer(
          -c(model, class_name),
          names_to = 'metric',
          values_to = "within_error"
        ) |> 
        bind_cols(row |> select(set, split, target, transform))
      metric_table_within <- bind_rows(metric_table_within, df)
}

metric_table_within <- metric_table_within |> 
  mutate(
    set = as_factor(str_c(set, target, sep = '_')),
    set = fct_recode(set,
      "FE Speed & Distance" = "speeddist_fe",
      "FE Calc Components" = "djdrank4_fe",
      "FE Work" = "work_fe",
      "FE OECD" = "oecd_fe",
      "FE Preferred" = "djdrank10_fe",
      "FC Speed & Distance" = "speeddist_fc",
      "FC Calc Components" = "djdrank4_fc",
      "FC Work" = "work_fc",
      "FC OECD" = "oecd_fc",
      "FC Preferred" = "djdrank10_fc",
      "FC Norm Structural" = "struct_fcnorm",
      "FC Structural" = "structfc_fc"
    ),
    set = fct_relevel(set,
      "FE Speed & Distance",
      "FE Calc Components",
      "FE Work",
      "FE OECD",
      "FE Preferred",
      "FC Speed & Distance",
      "FC Calc Components",
      "FC Work",
      "FC OECD",
      "FC Preferred",
      "FC Norm Structural",
      "FC Structural"
    )
  )
```

### Calcs

```{r}
metric_table <- metric_table |>
  filter(model != "cb") |>
  # filter(!(metric %in% c("r2", "te"))) |> 
  left_join(metric_table_within,
    by = c("model", "class_name", "metric", "set", "split", "target", "transform")
  ) |> 
  mutate(transfer_deterioration = transfer_error/within_error) |> 
  group_by(metric, split) |>
  mutate(best_within_error = best_stat_function(first(metric), within_error)) |> 
  # mutate(correct = min(within_error)) |> 
  mutate(norm_transfer_error = transfer_error/min(within_error))
```

### Calc checks

```{r}
metric_table |> 
  filter(metric == 'mape') |> 
  separate(set, c(NA, "vars"), sep = ' ', extra = "merge") |> 
  group_by(target, split, transform, vars) |> 
  filter(within_error == min(within_error)) |> 
  select(target, model, split, transform, vars, within_error) |> 
  pivot_wider(names_from = target, values_from = c(within_error, model)) |> 
  arrange(split)
```

Check own normalized transfer error is 1 for eng

```{r}
metric_table |> 
  filter(metric == 'mae') |> 
  select(model, set, split, target, transform, within_error, norm_transfer_error, transfer_deterioration) |> 
  filter(model == 'eng')
```

Which have own normalized trarnsfer error \< 1?

```{r}
metric_table |> 
  filter(model != 'eng') |>
  filter(transfer_deterioration < 1) |>
  filter(metric != 'r2') |> 
  filter(metric != 'te')
```

# Within domain error

```{r}
test <- metric_table |> 
  filter(metric == 'mae') |> 
  ggplot(aes(x = model, y = within_error, fill = set)) +
  geom_col(position = "dodge") +
  facet_wrap(~split) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
ggplotly(test)
```

```{r}
# histogram of within domain error
metric_table |> 
  filter(metric == 'mae') |> 
  ggplot(aes(x = within_error, fill = model)) +
  geom_histogram() +
  facet_wrap(~split)
```

All models

```{r}
stat_plot_model(
  metric_table,
  "within_error",
  "mae",
  "all"
) |> 
  print()
```

# Normalized Transfer Error

## Best model for each test domain

```{r}
stat_plot_model(
  metric_table,
  "norm_transfer_error",
  "mae",
  best_model_only = TRUE
) |> 
  print()
```

## Model-wise performance by test domain

### Gradient Boost

```{r}
if ("gb" %in% metric_table$model) {
  stat_plot_model(
    metric_table,
    "norm_transfer_error",
    "mape",
    "gb"
  ) |> 
    print()
}
```

## All models

```{r}
stat_plot_model(
  metric_table,
  "norm_transfer_error",
  "mape",
  "all"
) |> 
  print()
```

```{r}
stat_plot_model(
  metric_table,
  "norm_transfer_error",
  "r2",
  "all"
) |> 
  print()
```

# Transfer Deterioration

## Best model for each test domain

```{r}
stat_plot_model(
  metric_table |> filter(model != "eng"),
  "transfer_deterioration",
  "mape",
  best_model_only = TRUE
) |> 
  print()
  # ggplotly()
```

## Model-wise performance by test domain

### Ridge

```{r}
if ("ridge" %in% metric_table$model) {
  stat_plot_model(
    metric_table,
    "transfer_deterioration",
    "mape",
    "ridge"
  ) |> 
    print()
}
```

### Gradient Boost

```{r}
if ("gb" %in% metric_table$model) {
  stat_plot_model(
    metric_table,
    "transfer_deterioration",
    "mape",
    "gb"
  ) |> 
    print()
}
```

## All models

```{r}
stat_plot_model(
  metric_table,
  "transfer_deterioration",
  "mape",
  # "all"
  c("eng", "gb", "lasso", "linear", "rf", "ridge", "linearstruct")
) |> 
  print()
  # ggplotly()
```

```{r}
stat_plot_model(
  metric_table,
  "transfer_deterioration",
  "mae",
  # "all"
  c("eng", "gb", "lasso", "linear", "rf", "ridge", "linearstruct")
) |> 
  print()
```

# END
