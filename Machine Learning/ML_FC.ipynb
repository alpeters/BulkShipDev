{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Machine learning model for predicting fuel consumption.\n",
        "\n",
        "Hyperparameter tuning and training of various linear and tree-based algorithms.\n",
        "\n",
        "Comparison of optimally tuned models.\n",
        "\n",
        "Perform model tuning and validation on splits of 'train' set (years 2019, 2020).\n",
        "\n",
        "Perform final model testing on 'test' set (year 2021).\n",
        "\n",
        "Input(s): \n",
        "- df_ml_[variant]_train.csv\n",
        "- df_ml_[variant]_test.csv\n",
        "\n",
        "Output(s): \n",
        "- Git Untracked Data:\n",
        "    - Model dataframes with fitted estimators after certain steps\n",
        "        - _mdl_df_base.pkl\n",
        "        - _mdl_df_best.pkl\n",
        "        - _mdl_df_kf.pkl\n",
        "        - _mdl_df_compare.pkl\n",
        "- Git Tracked Data:\n",
        "    - parameters: _params.csv\n",
        "    - stats comparisons for residual and fuel consumption: e.g. _best_fc.csv\n",
        "    - feature importance rankings: _FI.csv    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preamble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import string\n",
        "import sys\n",
        "# from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBRegressor\n",
        "sys.path.append(\"../code/.\")\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "# from sklearn.dummy import DummyRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import (\n",
        "    GridSearchCV,\n",
        "    # RandomizedSearchCV,\n",
        "    # cross_val_score,\n",
        "    # cross_validate,\n",
        "    # train_test_split,\n",
        ")\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from catboost import CatBoostRegressor\n",
        "from lightgbm.sklearn import LGBMRegressor\n",
        "# from sklearn.tree import DecisionTreeRegressor\n",
        "# from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, FunctionTransformer\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, matthews_corrcoef, make_scorer #, PredictionErrorDisplay\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import cross_validate, LeaveOneOut, LeavePOut, KFold, RepeatedKFold\n",
        "import seaborn as sns\n",
        "import pickle # for saving models\n",
        "from sklearn.inspection import permutation_importance # for permutation feature importance\n",
        "import time #for timing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Global Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tol_type = 'abs' # 'rel' or 'abs' tolerance type for subsetting 'valid' data based on distance discrepancy\n",
        "outlier_threshold = 3 #np.Inf # number of standard deviations from the mean to consider a point an outlier\n",
        "feature_set = 'm5dd' # feature set to use (defined herein)\n",
        "validation_stats = {\n",
        "    # my name: function, printing name, greater_is_better\n",
        "    'r2': (r2_score, 'RÂ²', True),\n",
        "    # 'corr': (corr2, 'Correlation'), # doesn't work for cv\n",
        "    'mse': (mean_squared_error, 'MSE', False),\n",
        "    'mae': (mean_absolute_error, 'MAE', False),\n",
        "    'mape': (mean_absolute_percentage_error, 'MAPE', False),\n",
        "    # 'corr': (matthews_corrcoef, 'corr') # doesn't work!\n",
        "} \n",
        "\n",
        "cv_folds = 5\n",
        "cv_scoring = 'r2'\n",
        "\n",
        "eval_types_dict = {\n",
        "    'gridsearch': cv_folds,\n",
        "    'lpo': LeavePOut(2),\n",
        "    'kfold': 10,\n",
        "    'repkfold': RepeatedKFold(n_repeats=3, n_splits=10, random_state=2652124)\n",
        "}\n",
        "train_eval_type = 'kfold' #'gridsearch' # one of keys of eval_types_dict\n",
        "\n",
        "fast_only = False # if True, only run models that are fast\n",
        "max_cores = 6\n",
        "\n",
        "sns.set_theme(\n",
        "    context='paper',\n",
        "    palette='colorblind', # deep, dark, bright, colorblind\n",
        "    font_scale=1.4\n",
        "    ) \n",
        "sns.set_style('whitegrid',\n",
        "    {'axes.grid': False})\n",
        "plt.rcParams[\"font.family\"] = \"Bitstream Vera Sans\"\n",
        "plt.rcParams['xtick.labelsize'] = 11\n",
        "plt.rcParams['ytick.labelsize'] = 11\n",
        "plt.rcParams['axes.labelsize'] = 15\n",
        "plt.rcParams['legend.fontsize'] = 13\n",
        "plt.rcParams['legend.title_fontsize'] = 15\n",
        "plt.rcParams['legend.frameon'] = False\n",
        "\n",
        "datapath = 'Machine Learning/data/'\n",
        "readdatapath = 'src/tracked_data/'\n",
        "trackeddatapath = 'Machine Learning/tracked_data/'\n",
        "plotpath = 'Machine Learning/plots/'\n",
        "fileprefix = 'ML_FC_F' + feature_set + '_' #+ '_nofilter_' \n",
        "if fast_only:\n",
        "    fileprefix += 'fast_'\n",
        "model_df_filename = 'mdl_df'\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "param_vars = [\n",
        "    'tol_type',\n",
        "    'outlier_threshold',\n",
        "    'feature_set',\n",
        "    'cv_folds',\n",
        "    'cv_scoring',\n",
        "    'train_eval_type',\n",
        "    'eval_types_dict',\n",
        "    'datapath',\n",
        "    'trackeddatapath',\n",
        "    'plotpath',\n",
        "    'fileprefix',\n",
        "    'model_df_filename']\n",
        "\n",
        "# safeguard against overwriting if slow to run\n",
        "if ~fast_only & os.path.exists(trackeddatapath + fileprefix + 'params.csv'):\n",
        "    sys.exit('File already exists. Delete params csv file to overwrite all related data.')\n",
        "\n",
        "\n",
        "pd.DataFrame(\n",
        "    [(i, globals()[i]) for i in param_vars],\n",
        "    columns = ['parameter', 'value']\n",
        "    ).to_csv(\n",
        "        trackeddatapath + fileprefix + 'params.csv',\n",
        "        index = False)\n",
        "\n",
        "print(f\"Started at: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def col_search(searchkey):\n",
        "    \"\"\"\n",
        "    Search for column names containing a given string and print summary statistics. (case insensitive)\n",
        "    \"\"\"\n",
        "    colname_matches = [col for col in df_ml.columns if searchkey.lower() in col.lower()]\n",
        "    if len(colname_matches) > 0:\n",
        "        print(colname_matches)\n",
        "        df_ml[colname_matches].describe()\n",
        "        for col in colname_matches:\n",
        "            if df_ml[col].nunique() <= 10:\n",
        "                print(col)\n",
        "                print(df_ml[colname_matches].value_counts())\n",
        "    else:\n",
        "        print('No matches found')\n",
        "\n",
        "def plot_45deg_line(x, y, xylinelabel):\n",
        "    \"\"\"\n",
        "    Create a two-way plot with a 45-degree line.\n",
        "    \"\"\"\n",
        "    upper = 1.01*max(x.max(), y.max())\n",
        "    lower = 0.99*min(x.min(), y.min())\n",
        "    x0 = np.linspace(lower, upper, 100)\n",
        "    plt.plot(x0, x0, alpha=0.8, color = 'black', linestyle='dashed', label=xylinelabel)\n",
        "\n",
        "def two_way_plot(x, y, data=None, hue=None, alpha=0.5, title=None, xlabel=None, ylabel=None, legend=True, legend_title=None, line_labels=False, regline=False, savepath=None):\n",
        "    \"\"\"\n",
        "    Create a two-way plot with a regression line.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(5, 5), dpi=300)\n",
        "    sns.scatterplot(data=data, x=x, y=y, hue=hue, alpha=alpha)\n",
        "    if line_labels:\n",
        "        reglinelabel='Linear regression'\n",
        "        xylinelabel='x=y'\n",
        "    else:\n",
        "        reglinelabel=None\n",
        "        xylinelabel=None\n",
        "\n",
        "    if data is None:\n",
        "        plot_45deg_line(x, y, xylinelabel)\n",
        "    else:\n",
        "        plot_45deg_line(data[x], data[y], xylinelabel)\n",
        "    \n",
        "    if regline:\n",
        "        sns.regplot(\n",
        "            data=data, x=x, y=y, \n",
        "            scatter=False,\n",
        "            line_kws={'linestyle':'dotted'},\n",
        "            label=reglinelabel,\n",
        "            color='black')\n",
        "    \n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    if legend:\n",
        "        plt.legend(\n",
        "            title=legend_title,\n",
        "            bbox_to_anchor=(1.05, 0.5),\n",
        "            loc='center left')\n",
        "    if savepath:\n",
        "        plt.savefig(savepath, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def plot_45deg_line_new(x, y, ax):\n",
        "    \"\"\"\n",
        "    Create a two-way plot with a 45-degree line.\n",
        "    \"\"\"\n",
        "    upper = max(x.max(), y.max()) + 0.1\n",
        "    lower = min(x.min(), y.min()) - 0.1\n",
        "    x0 = np.linspace(lower, upper, 100)\n",
        "    ax.plot(x0, x0, color='black', label='x=y')\n",
        "\n",
        "def two_way_plot_new(x, y, data=None, hue=None, alpha=0.5, title=None, xlabel=None, ylabel=None, legend_title=None, regline=False, savepath=None):\n",
        "    \"\"\"\n",
        "    Create a two-way plot with a regression line.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(5, 5), dpi=300)\n",
        "    sns.scatterplot(data=data, x=x, y=y, hue=hue, alpha=alpha, ax=ax)\n",
        "    if regline:\n",
        "        sns.regplot(data=data, x=x, y=y, scatter=False, line_kws={'linestyle':'dashed'}, label='regression line', color='red', ax=ax)\n",
        "    if data is None:\n",
        "        plot_45deg_line_new(x, y, ax=ax)\n",
        "    else:\n",
        "        plot_45deg_line_new(data[x], data[y], ax=ax)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.legend(title=legend_title)\n",
        "    if savepath:\n",
        "        plt.savefig(savepath)\n",
        "    plt.show()\n",
        "    return ax\n",
        "\n",
        "# def make_estimator_default(scaling, mdlclass):\n",
        "#     if scaling:\n",
        "#         estimator = make_pipeline(preprocessor_scaling, mdlclass)\n",
        "#     elif ~scaling:\n",
        "#         estimator = make_pipeline(preprocessor_noscaling, mdlclass)\n",
        "#     return estimator\n",
        "\n",
        "def make_estimator(scaling, classname, params=None):\n",
        "    if params is None:\n",
        "        if classname == 'LinearRegression':\n",
        "            estimator = make_pipeline(preprocessor_noscaling_drop, globals()[classname]())\n",
        "        elif scaling:\n",
        "            estimator = make_pipeline(preprocessor_scaling, globals()[classname]())\n",
        "        elif ~scaling:\n",
        "            estimator = make_pipeline(preprocessor_noscaling, globals()[classname]())\n",
        "    else:\n",
        "        if scaling:\n",
        "            estimator = make_pipeline(preprocessor_scaling, globals()[classname](**params))\n",
        "        elif ~scaling:\n",
        "            estimator = make_pipeline(preprocessor_noscaling, globals()[classname](**params))\n",
        "    return estimator\n",
        "    \n",
        "# def MAE(y_true, y_pred):\n",
        "#     \"\"\"\n",
        "#     Calculate mean absolute error.\n",
        "#     \"\"\"\n",
        "#     return np.mean(np.abs(y_true - y_pred))\n",
        "                   \n",
        "# def MAPE(y_true, y_pred):\n",
        "#     \"\"\"\n",
        "#     Calculate mean absolute percentage error.\n",
        "#     \"\"\"\n",
        "#     return np.mean(np.abs((y_true - y_pred) / y_true))\n",
        "\n",
        "# def corr2(x, y):\n",
        "#     \"\"\"\n",
        "#     Calculate the correlation coefficient.\n",
        "#     \"\"\"\n",
        "#     return np.corrcoef(x, y)[0, 1]\n",
        "\n",
        "def calculate_stats(y_true, y_pred, data=None, stats_dict=None):\n",
        "    \"\"\"\n",
        "    Create a dictionary of statistics for a model.\n",
        "    \"\"\"\n",
        "    if data is not None:\n",
        "        y_true = data[y_true]\n",
        "        y_pred = data[y_pred]\n",
        "\n",
        "    values_dict = {}\n",
        "    names_dict = {}\n",
        "    for stat in stats_dict.keys():\n",
        "        values_dict[stat] = stats_dict[stat][0](y_true, y_pred)\n",
        "        names_dict[stat] = stats_dict[stat][1]\n",
        "    return {'stats' : values_dict, 'names' : names_dict}    \n",
        "\n",
        "def create_legend_title(stats_dict):\n",
        "    \"\"\"\n",
        "    Create a legend title for a plot based on a dictionary of statistics.\n",
        "    \"\"\"\n",
        "    legend_title = ''\n",
        "    for key in stats_dict['stats']:\n",
        "        legend_title += f\"{stats_dict['names'][key]}: {round(stats_dict['stats'][key],3)}\\n\"\n",
        "    return legend_title\n",
        "\n",
        "def cross_validate_stats(X, y, estimator, cv, validation_stats, max_cores):\n",
        "    cv_scores = cross_validate(\n",
        "        estimator,\n",
        "        X, y,\n",
        "        cv=cv,\n",
        "        scoring={key: make_scorer(stat[0], greater_is_better=stat[2]) for key, stat in validation_stats.items()},\n",
        "        # scoring=make_scorer(r2_score, greater_is_better=True),\n",
        "        n_jobs=max_cores)\n",
        "\n",
        "    means = [np.mean(value) for key, value in cv_scores.items() if key.startswith('test_')]\n",
        "    # take negative where approriate because cross_validate returns negatives if ~greater_is_better\n",
        "    means = [means[index]*(1 if value[2] else -1) for index, value in enumerate(validation_stats.values())]\n",
        "    sds = [np.std(value) for key, value in cv_scores.items() if key.startswith('test_')]\n",
        "    return {\"means\": dict(zip(validation_stats.keys(), means)),\n",
        "            \"sds\": dict(zip(validation_stats.keys(), sds)),\n",
        "            \"names\": {keys: values[1] for keys, values in validation_stats.items()}}\n",
        "\n",
        "def format_cv_results(grid_search):\n",
        "    \"\"\"\n",
        "    Format the results of a grid search as a pandas DataFrame.\n",
        "    \"\"\"\n",
        "    cv_results = pd.DataFrame(grid_search.cv_results_)[['param_gradientboostingregressor__learning_rate', 'param_gradientboostingregressor__max_depth', 'mean_test_score', 'std_test_score', 'rank_test_score']].sort_values('rank_test_score')\n",
        "    # shorten column names\n",
        "    cv_results.columns = cv_results.columns.str.removeprefix('param_gradientboostingregressor__')\n",
        "    cv_results.columns = cv_results.columns.str.replace('_score', '_' + cv_scoring)\n",
        "    print(f\"Model: { grid_search.estimator.named_steps['gradientboostingregressor'].__class__.__name__ }\")\n",
        "    return cv_results\n",
        "\n",
        "# def model_comparison_table(stats_to_compare, params=None):\n",
        "#     \"\"\"\n",
        "#     Create a pandas DataFrame of statistics for multiple models.\n",
        "#     Args:\n",
        "#         stats_to_compare: dictionary of tuples of statistics dictionaries and models\n",
        "#     Returns:\n",
        "#         pandas DataFrame\n",
        "#     \"\"\"\n",
        "#     for key, value in stats_to_compare.items():\n",
        "#         value[0]['stats']['model'] = key\n",
        "#         if params is not None:\n",
        "#             for param in params:\n",
        "#                 try:\n",
        "#                     value[0]['stats'][param] = value[1][-1].get_params()[param]\n",
        "#                 except:\n",
        "#                     value[0]['stats'][param] = np.nan\n",
        "\n",
        "#     compare_df = pd.DataFrame([value[0]['stats'] for key, value in stats_to_compare.items()]).set_index('model')\n",
        "#     return compare_df\n",
        "\n",
        "def tribble(columns, *data):\n",
        "    return pd.DataFrame(\n",
        "        data=list(zip(*[iter(data)]*len(columns))),\n",
        "        columns=columns\n",
        "    )\n",
        "\n",
        "def model_stats_comparison_table(stats_col, params_col, estimator_col, mdl_df, stat_key='stats'):\n",
        "    \"\"\"\n",
        "    Create a pandas DataFrame of statistics for multiple models.\n",
        "    Args: \n",
        "        stats_col: name of column containing statistics\n",
        "        estimator_col: name of column containing fitted estimators\n",
        "    Returns:\n",
        "        pandas DataFrame\n",
        "    \"\"\"\n",
        "\n",
        "    compare_df = mdl_df.loc[:, [stats_col, estimator_col, params_col, 'class_name']]\n",
        "    \n",
        "    compare_df[stats_col] = compare_df[stats_col].apply(lambda x: x[stat_key])\n",
        "\n",
        "    for key in compare_df[stats_col].iloc[0].keys():\n",
        "        compare_df[key] = compare_df[stats_col].apply(lambda x: x[key])\n",
        "\n",
        "    compare_df['params'] = compare_df.apply(lambda row: extract_filter_params(row, estimator_col, params_col), axis=1)\n",
        "\n",
        "    return compare_df.drop([stats_col, estimator_col, params_col], axis=1)\n",
        "\n",
        "def extract_filter_params(row, estimator_col, params_col_mask): \n",
        "    \"\"\" \n",
        "    Extract and filter the parameters to the ones in params_col and drop parameter name prefix.\n",
        "    Args:\n",
        "        row: pandas DataFrame row\n",
        "        estimator_col: name of column containing fitted estimators\n",
        "        params_col_mask: name of column containing parameters to keep (should be without model name prefix)\n",
        "    \"\"\"\n",
        "    params = row[estimator_col].named_steps[row['class_name'].lower()].get_params()\n",
        "    if row[params_col_mask] is None:\n",
        "        return None\n",
        "    else:\n",
        "        return {k.replace(row['class_name'].lower() + '__', ''): v for k, v in params.items() if k in row[params_col_mask].keys()}\n",
        "\n",
        "# def filter_params(row, params_col, params_col_mask): \n",
        "#     \"\"\" \n",
        "#     Filter the parameters to the ones in params_col and drop parameter name prefix.\n",
        "#     \"\"\"\n",
        "#     if row[params_col_mask] is None:\n",
        "#         return None\n",
        "#     else:\n",
        "#         return {k.replace(row['class_name'].lower() + '__', ''): v for k, v in row[params_col].items() if k in row[params_col_mask].keys()}\n",
        "    \n",
        "# def loo_evaluation(estimator):\n",
        "#     \"\"\"\n",
        "#     Performs leave-one-out evaluation and returns the predicted residuals.\n",
        "#     \"\"\"\n",
        "#     loo_prediction = np.zeros(len(y))\n",
        "\n",
        "#     for train_index, val_index in loo.split(X):\n",
        "#         X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "#         y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "#         estimator.fit(X_train, y_train)\n",
        "#         loo_prediction[val_index] = estimator.predict(X_val)\n",
        "    \n",
        "#     return loo_prediction\n",
        "\n",
        "# def kfold_evaluation(estimator, name):\n",
        "#     \"\"\"\n",
        "#     Performs k-fold evaluation and returns the predicted residuals.\n",
        "#     \"\"\"\n",
        "#     print(f\"Starting evaluating {name} at: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))}\")\n",
        "#     kf_prediction = np.zeros(len(y))\n",
        "\n",
        "#     for train_index, val_index in kf.split(X):\n",
        "#         X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "#         y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "#         estimator.fit(X_train, y_train)\n",
        "#         kf_prediction[val_index] = estimator.predict(X_val)\n",
        "    \n",
        "#     return kf_prediction\n",
        "\n",
        "def FI_plot(FI, model_name):\n",
        "    FI_df = pd.DataFrame(FI.importances, index = features).assign(mean=lambda df: df.mean(axis=1)).sort_values('mean')\n",
        "    plt.figure(figsize=(5, 5), dpi=300)\n",
        "    plt.boxplot(\n",
        "        FI_df.drop(columns='mean').T,\n",
        "        vert=False,\n",
        "        labels=np.array(FI_df.index),\n",
        "    )\n",
        "    plt.title('Permutation Importances: ' + model_name)\n",
        "    plt.savefig(plotpath + fileprefix + 'FI_perm_' + model_name + '.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Validation and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ml = pd.read_csv(readdatapath + \"df_ml_\" + tol_type + \"_train.csv\", low_memory=False)\n",
        "\n",
        "# for nicer colors when plotting\n",
        "df_ml = df_ml.sort_values('year')\n",
        "df_ml['year_str'] = df_ml['year'].astype(str) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Column name search\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "col_search('MRV')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df_ml.loc[:, df_ml.columns.str.contains('Type', case=False)].describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ml['Type'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_mean = df_ml['residual'].mean()\n",
        "raw_std = df_ml['residual'].std()\n",
        "print(f'Raw Data: \\n observations: {len(df_ml)} \\n target mean: {raw_mean} \\n target sd: {raw_std}')\n",
        "\n",
        "stats_raw = calculate_stats('log_report_fc', 'log_cal_fc', df_ml, validation_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Scatter plot of reported vs calculated fuel consumption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "two_way_plot(\n",
        "     'log_report_fc',\n",
        "     'log_cal_fc',\n",
        "     df_ml,\n",
        "     # title='Raw Data',\n",
        "     xlabel='US Log Reported Fuel Consumption',\n",
        "     ylabel='Log Calculated Fuel Consumption',\n",
        "     legend=False,\n",
        "     # legend_title=create_legend_title(stats_raw),\n",
        "     regline=True,\n",
        "     savepath=plotpath + fileprefix + 'twoway_fc_raw.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Scatter plot of reported vs calculated fuel consumption by year using two_way_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "two_way_plot(\n",
        "    'log_report_fc',\n",
        "    'log_cal_fc',\n",
        "    df_ml,\n",
        "    hue='year_str',\n",
        "    alpha=0.3,\n",
        "    title='Raw Data',\n",
        "    xlabel='Log Reported Fuel Consumption',\n",
        "    ylabel='Log Calculated Fuel Consumption',\n",
        "    regline=True,\n",
        "    line_labels=False,\n",
        "    legend_title='Year',\n",
        "    savepath=plotpath + fileprefix + 'twoway_fcbyyear_raw.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Explore outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ml['outlier'] = ~df_ml['residual'].between(\n",
        "    raw_mean - outlier_threshold * raw_std,\n",
        "    raw_mean + outlier_threshold * raw_std,\n",
        "    inclusive='neither')\n",
        "# df_ml.loc[df_ml['outlier'],:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ml['outlier'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# compare means of outliers and non\n",
        "df_ml.loc[:, ['outlier'] + df_ml.select_dtypes(include=[np.number]).columns.tolist()].groupby('outlier').agg('mean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "two_way_plot(\n",
        "     'log_report_fc',\n",
        "     'log_cal_fc',\n",
        "     df_ml,\n",
        "     hue='outlier',\n",
        "     title='Raw Data',\n",
        "     xlabel='log Reported Fuel Consumption',\n",
        "     ylabel='log Calculated Fuel Consumption',\n",
        "     legend_title='Outlier',\n",
        "     regline=False,\n",
        "     savepath=plotpath + fileprefix + 'twoway_fc_raw.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare distributions for a given variable\n",
        "sns.histplot(data=df_ml, x='Dwt', hue='outlier', stat='proportion', common_norm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check largest correlates\n",
        "(\n",
        "    df_ml\n",
        "    .corr(numeric_only=True)\n",
        "    .loc[:, ['outlier']]\n",
        "    .assign(abs_corr=lambda x: abs(x))\n",
        "    .sort_values('abs_corr', ascending=False)\n",
        "    .head(30)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train algorithm to identify outliers?\n",
        "(in order to find cause)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.linear_model import Lasso\n",
        "\n",
        "# # Select the numeric variables\n",
        "# numeric_vars = df_ml.select_dtypes(include=[np.number]).columns.tolist()\n",
        "# # remove any features that have all values missing\n",
        "# numeric_vars = [var for var in numeric_vars if df_ml[var].notnull().sum() > 0]\n",
        "# numeric_vars = numeric_vars[1:25]\n",
        "\n",
        "# # Split the data into input features (X) and target variable (y)\n",
        "# X = df_ml[numeric_vars]\n",
        "# y = df_ml['outlier'].astype(int)\n",
        "\n",
        "# # create a pipeline to impute missing values and scale the data, then do lasso\n",
        "# preprocessor = make_column_transformer(\n",
        "#     (SimpleImputer(strategy='median'), numeric_vars),\n",
        "#     remainder='passthrough'\n",
        "# )\n",
        "\n",
        "# lasso_coefs = pd.DataFrame(pipeline.named_steps['lasso'].coef_, index=numeric_vars).assign(abs=lambda x: abs(x), col='0').sort_values('abs', ascending=False)\n",
        "# lasso_coefs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "# # Select the top k features based on chi-square test\n",
        "# k = 5  # Number of top features to select\n",
        "# X = df_ml.drop(['outlier'], axis=1)  # Input features\n",
        "# y = df_ml['outlier']  # Target variable\n",
        "\n",
        "# # create list of non-numeric features\n",
        "# non_numeric = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "# # create column transformer to one-hot encode non-numeric features and impute missing values with median\n",
        "\n",
        "# preprocessor = make_column_transformer(\n",
        "#     (OneHotEncoder(), non_numeric),\n",
        "#     remainder='passthrough'\n",
        "# )\n",
        "\n",
        "# pipeline = make_pipeline(\n",
        "#     preprocessor,\n",
        "#     SimpleImputer(strategy='median'),\n",
        "#     SelectKBest(score_func=chi2, k=k)\n",
        "# )\n",
        "\n",
        "# X_selected = pipeline.fit(X, y)\n",
        "\n",
        "# # Get the selected feature names\n",
        "# selected_feature_names = X.columns[selector.get_support()]\n",
        "\n",
        "# # Print the selected feature names\n",
        "# print(\"Selected Features:\")\n",
        "# for feature in selected_feature_names:\n",
        "#     print(feature)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Filter out outliers "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ml = df_ml.loc[~df_ml['outlier']]\n",
        "print(f'Filtered Data: \\n observations: {len(df_ml)} \\n target mean: {df_ml.residual.mean()} \\n target sd: {df_ml.residual.std()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### Scatter plot of reported vs calculated fuel consumption\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stats_filtered = calculate_stats('log_report_fc', 'log_cal_fc', df_ml, validation_stats)\n",
        "two_way_plot(\n",
        "    'log_report_fc',\n",
        "    'log_cal_fc',\n",
        "    df_ml,\n",
        "    title='Filtered Data',\n",
        "    xlabel='log Reported Fuel Consumption',\n",
        "    ylabel='log Calculated Fuel Consumption',\n",
        "    legend_title=create_legend_title(stats_filtered),\n",
        "    regline=True,\n",
        "    savepath=plotpath + fileprefix + 'twoway_fc_filtered.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Scatter plot of reported vs calculated fuel consumption by year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "two_way_plot(\n",
        "    'log_report_fc',\n",
        "    'log_cal_fc',\n",
        "    df_ml,\n",
        "    hue='year_str',\n",
        "    alpha=0.3,\n",
        "    title='Filtered Data',\n",
        "    xlabel='log Reported Fuel Consumption',\n",
        "    ylabel='log Calculated Fuel Consumption',\n",
        "    regline=True,\n",
        "    savepath=plotpath + fileprefix + 'twoway_fcbyyear_filtered.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Histogram of residuals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5, 5), dpi=300)\n",
        "sns.histplot(data=df_ml, x='residual', kde=False)\n",
        "plt.title('Filtered Data')\n",
        "plt.xlabel('Residual')\n",
        "plt.axvline(df_ml['residual'].mean(), color='black', linestyle='solid', linewidth=1, label='mean')\n",
        "plt.axvline(df_ml['residual'].median(), color='black', linestyle='dashed', linewidth=1, label='median')\n",
        "plt.legend()\n",
        "plt.savefig(plotpath + fileprefix + 'hist_residual_filtered.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Histogram of residuals by year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5, 5), dpi=300)\n",
        "sns.histplot(data=df_ml, x='residual', hue='year_str', alpha=0.5, kde=False)\n",
        "hue_values = df_ml['year'].unique()\n",
        "color_map = dict(zip(hue_values, sns.color_palette()))\n",
        "for year, color in color_map.items():\n",
        "    plt.axvline(df_ml[df_ml['year'] == year]['residual'].mean(), color=color)\n",
        "plt.title('Filtered Data')\n",
        "plt.xlabel('Residual')\n",
        "plt.savefig(plotpath + fileprefix + 'hist_residualbyyear_filtered_.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Manually Selected Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_dict = {\n",
        "    'm1' : [\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        'Service.Speed..knots.', # Nominal ship speed\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Operational.Speed..knots.', # Average observed travel speed (from WFR)\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        'Bale.Capacity..cu.m.', # Bale capacity\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        'West.Coast.Africa.Deployment..Time.in.Last.12.Months....', # snapshot in time, value from WFR\n",
        "        'EU.distance', # Annual distance travelled (EU trips) reported in MRV\n",
        "        'distance_sum', # Calculated distance travelled (EU trips) from our AIS data\n",
        "        'work_sum', # Calculated work done (EU trips) from our AIS data\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'W_component_first', # Fixed, ship-specific component of power, calculated from WFR data\n",
        "        'ME_W_ref_first', # Main engine power from WFR\n",
        "        't_m_times_v_n_sum', # sum[draught^m * speed^n], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_with_m_sum', # sum[(t/t_ref)^m], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_without_m_sum', # sum[(t/t_ref)], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_with_n_sum', # sum[(v/v_ref)^n], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_without_n_sum', # sum[(v/v_ref)], annual sum of instantaneous values from AIS data\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'Size.Category' # Ship size category from WFR\n",
        "        ],\n",
        "    'm1a' : [ # remove EU.distance because MRV reported variable\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        'Service.Speed..knots.', # Nominal ship speed\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Operational.Speed..knots.', # Average observed travel speed (from WFR)\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        'Bale.Capacity..cu.m.', # Bale capacity\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        'West.Coast.Africa.Deployment..Time.in.Last.12.Months....', # snapshot in time, value from WFR\n",
        "        'distance_sum', # Calculated distance travelled (EU trips) from our AIS data\n",
        "        'work_sum', # Calculated work done (EU trips) from our AIS data\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'W_component_first', # Fixed, ship-specific component of power, calculated from WFR data\n",
        "        'ME_W_ref_first', # Main engine power from WFR\n",
        "        't_m_times_v_n_sum', # sum[draught^m * speed^n], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_with_m_sum', # sum[(t/t_ref)^m], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_without_m_sum', # sum[(t/t_ref)], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_with_n_sum', # sum[(v/v_ref)^n], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_without_n_sum', # sum[(v/v_ref)], annual sum of instantaneous values from AIS data\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'Size.Category' # Ship size category from WFR\n",
        "        ],\n",
        "    'm1b' : [ # remove EU.distance because MRV reported variable, remove West coast deployment, bale capacity, ballast capacity (odd, missings), add dwt, longest_jump, and port_frac\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        'Service.Speed..knots.', # Nominal ship speed\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Operational.Speed..knots.', # Average observed travel speed (from WFR)\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message\n",
        "        'distance_sum', # Calculated distance travelled (EU trips) from our AIS data\n",
        "        'work_sum', # Calculated work done (EU trips) from our AIS data\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'W_component_first', # Fixed, ship-specific component of power, calculated from WFR data\n",
        "        'ME_W_ref_first', # Main engine power from WFR\n",
        "        't_m_times_v_n_sum', # sum[draught^m * speed^n], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_with_m_sum', # sum[(t/t_ref)^m], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_without_m_sum', # sum[(t/t_ref)], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_with_n_sum', # sum[(v/v_ref)^n], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_without_n_sum', # sum[(v/v_ref)], annual sum of instantaneous values from AIS data\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'longest_jump',\n",
        "        'port_frac',\n",
        "        'Dwt'\n",
        "        ],\n",
        "    'm2' : [\n",
        "        # Speed\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        \n",
        "        # Engine\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        # 'ME_W_ref_first', # Main engine power from WFR\n",
        "        \n",
        "        # Dimensions\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Beam.Mld..m.', # Width of ship\n",
        "        'TPC', # tonnage per centimeter (load required to increase draught)\n",
        "        # Size/capacity\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'Dwt',\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        # 'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        # 'Bale.Capacity..cu.m.', # Bale capacity\n",
        "\n",
        "        # Other\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "\n",
        "        # from AIS\n",
        "        'distance_sum', # Calculated distance travelled (EU trips) from our AIS data\n",
        "        'work_sum', # Calculated work done (EU trips) from our AIS data\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'port_frac', # fraction of EU-related observations at port\n",
        "        \n",
        "        ## Data quality\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'longest_jump', # longest distance between two observations        \n",
        "\n",
        "        ## Admiralty formula components\n",
        "        'W_component_first', # Fixed, ship-specific component of power, calculated from WFR data\n",
        "        't_m_times_v_n_sum', # sum[draught^m * speed^n], annual sum of instantaneous values from AIS data\n",
        "        # 't_over_t_ref_with_m_sum', # sum[(t/t_ref)^m], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_without_m_sum', # sum[(t/t_ref)], annual sum of instantaneous values from AIS data\n",
        "        # 'v_over_v_ref_with_n_sum', # sum[(v/v_ref)^n], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_without_n_sum' # sum[(v/v_ref)], annual sum of instantaneous values from AIS data\n",
        "        ],\n",
        "    'm2a' : [ # add cal_fc\n",
        "        # Speed\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        \n",
        "        # Engine\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        # 'ME_W_ref_first', # Main engine power from WFR\n",
        "        \n",
        "        # Dimensions\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Beam.Mld..m.', # Width of ship\n",
        "        'TPC', # tonnage per centimeter (load required to increase draught)\n",
        "        # Size/capacity\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'Dwt',\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        # 'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        # 'Bale.Capacity..cu.m.', # Bale capacity\n",
        "\n",
        "        # Other\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "\n",
        "        # from AIS\n",
        "        'distance_sum', # Calculated distance travelled (EU trips) from our AIS data\n",
        "        'work_sum', # Calculated work done (EU trips) from our AIS data\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'port_frac', # fraction (misnamed!) of EU-related observations at port\n",
        "        \n",
        "        ## Data quality\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'longest_jump', # longest distance between two observations        \n",
        "\n",
        "        ## Admiralty formula components\n",
        "        'W_component_first', # Fixed, ship-specific component of power, calculated from WFR data\n",
        "        't_m_times_v_n_sum', # sum[draught^m * speed^n], annual sum of instantaneous values from AIS data\n",
        "        # 't_over_t_ref_with_m_sum', # sum[(t/t_ref)^m], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_without_m_sum', # sum[(t/t_ref)], annual sum of instantaneous values from AIS data\n",
        "        # 'v_over_v_ref_with_n_sum', # sum[(v/v_ref)^n], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_without_n_sum', # sum[(v/v_ref)], annual sum of instantaneous values from AIS data\n",
        "\n",
        "        'cal_fc'\n",
        "        ],\n",
        "    'm2b' : [ # remove everything used to directly calculate cal_fc\n",
        "        # Speed\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        \n",
        "        # Engine\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        # 'ME_W_ref_first', # Main engine power from WFR\n",
        "        \n",
        "        # Dimensions\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Beam.Mld..m.', # Width of ship\n",
        "        'TPC', # tonnage per centimeter (load required to increase draught)\n",
        "        # Size/capacity\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'Dwt',\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        # 'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        # 'Bale.Capacity..cu.m.', # Bale capacity\n",
        "\n",
        "        # Other\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "\n",
        "        # from AIS\n",
        "        'distance_sum', # Calculated distance travelled (EU trips) from our AIS data\n",
        "        'work_sum', # Calculated work done (EU trips) from our AIS data\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'port_frac', # fraction (misnamed!) of EU-related observations at port\n",
        "        \n",
        "        ## Data quality\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'longest_jump', # longest distance between two observations        \n",
        "        ],\n",
        "    'm2c' : [ # exhaustive components of admiralty formula\n",
        "        # Speed\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        \n",
        "        # Engine\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        # 'ME_W_ref_first', # Main engine power from WFR\n",
        "        \n",
        "        # Dimensions\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Beam.Mld..m.', # Width of ship\n",
        "        'TPC', # tonnage per centimeter (load required to increase draught)\n",
        "        # Size/capacity\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'Dwt',\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        # 'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        # 'Bale.Capacity..cu.m.', # Bale capacity\n",
        "\n",
        "        # Other\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "\n",
        "        # from AIS\n",
        "        'distance_sum', # Calculated distance travelled (EU trips) from our AIS data\n",
        "        'work_sum', # Calculated work done (EU trips) from our AIS data\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'port_frac', # fraction of EU-related observations at port\n",
        "        \n",
        "        ## Data quality\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'longest_jump', # longest distance between two observations        \n",
        "\n",
        "        ## Admiralty formula components\n",
        "        'W_component_first', # Fixed, ship-specific component of power, calculated from WFR data\n",
        "        't_m_times_v_n_sum', # sum[draught^m * speed^n], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_with_m_sum', # sum[(t/t_ref)^m], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_without_m_sum', # sum[(t/t_ref)], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_with_n_sum', # sum[(v/v_ref)^n], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_without_n_sum' # sum[(v/v_ref)], annual sum of instantaneous values from AIS data\n",
        "        ],\n",
        "    'm3' : [\n",
        "        # Speed\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        \n",
        "        # Engine\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        # 'ME_W_ref_first', # Main engine power from WFR\n",
        "        \n",
        "        # Dimensions\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Beam.Mld..m.', # Width of ship\n",
        "        'TPC', # tonnage per centimeter (load required to increase draught)\n",
        "        # Size/capacity\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'Dwt',\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        # 'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        # 'Bale.Capacity..cu.m.', # Bale capacity\n",
        "\n",
        "        # Other\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "\n",
        "        # from AIS\n",
        "        'distance_sum', # Calculated distance travelled (EU trips) from our AIS data\n",
        "        'work_sum', # Calculated work done (EU trips) from our AIS data\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'port_frac', # fraction (misnamed!) of EU-related observations at port\n",
        "        \n",
        "        ## Data quality\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'longest_jump', # longest distance between two observations\n",
        "        'MRV.method.a',\n",
        "        'MRV.method.b',\n",
        "        'MRV.method.c',\n",
        "        'MRV.method.d',\n",
        "        'MRV.verifier.country',\n",
        "        'MRV.verifier.name',\n",
        "        \n",
        "        ## Admiralty formula components\n",
        "        'W_component_first', # Fixed, ship-specific component of power, calculated from WFR data\n",
        "        't_m_times_v_n_sum', # sum[draught^m * speed^n], annual sum of instantaneous values from AIS data\n",
        "        # 't_over_t_ref_with_m_sum', # sum[(t/t_ref)^m], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_without_m_sum', # sum[(t/t_ref)], annual sum of instantaneous values from AIS data\n",
        "        # 'v_over_v_ref_with_n_sum', # sum[(v/v_ref)^n], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_without_n_sum' # sum[(v/v_ref)], annual sum of instantaneous values from AIS data\n",
        "        ],\n",
        "    'm4a' : [ # only cal_fc and distance\n",
        "        # Speed\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        \n",
        "        # Engine\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        # 'ME_W_ref_first', # Main engine power from WFR\n",
        "        \n",
        "        # Dimensions\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Beam.Mld..m.', # Width of ship\n",
        "        'TPC', # tonnage per centimeter (load required to increase draught)\n",
        "        # Size/capacity\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'Dwt',\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        # 'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        # 'Bale.Capacity..cu.m.', # Bale capacity\n",
        "\n",
        "        # Other\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "\n",
        "        # from AIS\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'port_frac', # fraction (misnamed!) of EU-related observations at port\n",
        "        \n",
        "        ## Data quality\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'longest_jump', # longest distance between two observations        \n",
        "\n",
        "        ## Admiralty formula components\n",
        "        'cal_fc'\n",
        "        ],\n",
        "    'm4ad' : [ # only cal_fc and no distance\n",
        "        # Speed\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        \n",
        "        # Engine\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        # 'ME_W_ref_first', # Main engine power from WFR\n",
        "        \n",
        "        # Dimensions\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Beam.Mld..m.', # Width of ship\n",
        "        'TPC', # tonnage per centimeter (load required to increase draught)\n",
        "        # Size/capacity\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'Dwt',\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        # 'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        # 'Bale.Capacity..cu.m.', # Bale capacity\n",
        "\n",
        "        # Other\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "\n",
        "        # from AIS\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'port_frac', # fraction (misnamed!) of EU-related observations at port\n",
        "        \n",
        "        ## Data quality\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'longest_jump', # longest distance between two observations        \n",
        "\n",
        "        ## Admiralty formula components\n",
        "        'cal_fc',\n",
        "\n",
        "        ## Distance\n",
        "        'distance_sum'\n",
        "        ],\n",
        "    'm4b' : [ # only work_sum and no distance\n",
        "        # Speed\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        \n",
        "        # Engine\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        # 'ME_W_ref_first', # Main engine power from WFR\n",
        "        \n",
        "        # Dimensions\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Beam.Mld..m.', # Width of ship\n",
        "        'TPC', # tonnage per centimeter (load required to increase draught)\n",
        "        # Size/capacity\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'Dwt',\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        # 'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        # 'Bale.Capacity..cu.m.', # Bale capacity\n",
        "\n",
        "        # Other\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "\n",
        "        # from AIS\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'port_frac', # fraction (misnamed!) of EU-related observations at port\n",
        "        \n",
        "        ## Data quality\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'longest_jump', # longest distance between two observations        \n",
        "\n",
        "        ## Admiralty formula components\n",
        "        'work_sum'\n",
        "        ],\n",
        "'m4bd' : [ # only work_sum and distance\n",
        "        # Speed\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        \n",
        "        # Engine\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        # 'ME_W_ref_first', # Main engine power from WFR\n",
        "        \n",
        "        # Dimensions\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Beam.Mld..m.', # Width of ship\n",
        "        'TPC', # tonnage per centimeter (load required to increase draught)\n",
        "        # Size/capacity\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'Dwt',\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        # 'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        # 'Bale.Capacity..cu.m.', # Bale capacity\n",
        "\n",
        "        # Other\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "\n",
        "        # from AIS\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'port_frac', # fraction (misnamed!) of EU-related observations at port\n",
        "        \n",
        "        ## Data quality\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'longest_jump', # longest distance between two observations        \n",
        "\n",
        "        ## Admiralty formula components\n",
        "        'cal_fc',\n",
        "\n",
        "        ## Distance\n",
        "        'distance_sum'\n",
        "        ],\n",
        "'m4cd' : [ # components and distance\n",
        "        # Speed\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        \n",
        "        # Engine\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        # 'ME_W_ref_first', # Main engine power from WFR\n",
        "        \n",
        "        # Dimensions\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Beam.Mld..m.', # Width of ship\n",
        "        'TPC', # tonnage per centimeter (load required to increase draught)\n",
        "        # Size/capacity\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'Dwt',\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        # 'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        # 'Bale.Capacity..cu.m.', # Bale capacity\n",
        "\n",
        "        # Other\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "\n",
        "        # from AIS\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'port_frac', # fraction (misnamed!) of EU-related observations at port\n",
        "        \n",
        "        ## Data quality\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'longest_jump', # longest distance between two observations        \n",
        "\n",
        "        ## Admiralty formula components\n",
        "        'W_component_first', # Fixed, ship-specific component of power, calculated from WFR data\n",
        "        # 't_m_times_v_n_sum', # sum[draught^m * speed^n], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_with_m_sum', # sum[(t/t_ref)^m], annual sum of instantaneous values from AIS data\n",
        "        # 't_over_t_ref_without_m_sum', # sum[(t/t_ref)], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_with_n_sum', # sum[(v/v_ref)^n], annual sum of instantaneous values from AIS data\n",
        "        # 'v_over_v_ref_without_n_sum' # sum[(v/v_ref)], annual sum of instantaneous values from AIS data\n",
        "\n",
        "        ## Distance\n",
        "        'distance_sum'\n",
        "        ],\n",
        "    'm4dd' : [ # kitchen sink\n",
        "        # Speed\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        \n",
        "        # Engine\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        # 'ME_W_ref_first', # Main engine power from WFR\n",
        "        \n",
        "        # Dimensions\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Beam.Mld..m.', # Width of ship\n",
        "        'TPC', # tonnage per centimeter (load required to increase draught)\n",
        "        # Size/capacity\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'Dwt',\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        # 'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        # 'Bale.Capacity..cu.m.', # Bale capacity\n",
        "\n",
        "        # Other\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "\n",
        "        # from AIS\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'port_frac', # fraction (misnamed!) of EU-related observations at port\n",
        "        \n",
        "        ## Data quality\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'longest_jump', # longest distance between two observations        \n",
        "\n",
        "        ## Admiralty formula components\n",
        "        'W_component_first', # Fixed, ship-specific component of power, calculated from WFR data\n",
        "        't_m_times_v_n_sum', # sum[draught^m * speed^n], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_with_m_sum', # sum[(t/t_ref)^m], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_without_m_sum', # sum[(t/t_ref)], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_with_n_sum', # sum[(v/v_ref)^n], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_without_n_sum', # sum[(v/v_ref)], annual sum of instantaneous values from AIS data\n",
        "        'cal_fc',\n",
        "\n",
        "        ## Distance\n",
        "        'distance_sum'\n",
        "        ],\n",
        "    'm4ed' : [ # only components not direclty in cal_fc, cal_fc,  and distance\n",
        "        # Speed\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        \n",
        "        # Engine\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        # 'ME_W_ref_first', # Main engine power from WFR\n",
        "        \n",
        "        # Dimensions\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Beam.Mld..m.', # Width of ship\n",
        "        'TPC', # tonnage per centimeter (load required to increase draught)\n",
        "        # Size/capacity\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'Dwt',\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        # 'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        # 'Bale.Capacity..cu.m.', # Bale capacity\n",
        "\n",
        "        # Other\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "\n",
        "        # from AIS\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'port_frac', # fraction (misnamed!) of EU-related observations at port\n",
        "        \n",
        "        ## Data quality\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'longest_jump', # longest distance between two observations        \n",
        "\n",
        "        ## Admiralty formula components\n",
        "        't_over_t_ref_without_m_sum', # sum[(t/t_ref)], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_without_n_sum', # sum[(v/v_ref)], annual sum of instantaneous values from AIS data\n",
        "        'cal_fc',\n",
        "        \n",
        "        ## Distance\n",
        "        'distance_sum'\n",
        "        ],\n",
        "    'm4fd' : [ # only distance\n",
        "        # Speed\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        \n",
        "        # Engine\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        # 'ME_W_ref_first', # Main engine power from WFR\n",
        "        \n",
        "        # Dimensions\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Beam.Mld..m.', # Width of ship\n",
        "        'TPC', # tonnage per centimeter (load required to increase draught)\n",
        "        # Size/capacity\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'Dwt',\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        # 'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        # 'Bale.Capacity..cu.m.', # Bale capacity\n",
        "\n",
        "        # Other\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "\n",
        "        # from AIS\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'port_frac', # fraction (misnamed!) of EU-related observations at port\n",
        "        \n",
        "        ## Data quality\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'longest_jump', # longest distance between two observations\n",
        "        \n",
        "        ## Distance\n",
        "        'distance_sum'\n",
        "        ],\n",
        "    'm4f' : [ # only static\n",
        "        # Speed\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        \n",
        "        # Engine\n",
        "        'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        # 'ME_W_ref_first', # Main engine power from WFR\n",
        "        \n",
        "        # Dimensions\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Beam.Mld..m.', # Width of ship\n",
        "        'TPC', # tonnage per centimeter (load required to increase draught)\n",
        "        # Size/capacity\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'Dwt',\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        # 'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        # 'Bale.Capacity..cu.m.', # Bale capacity\n",
        "\n",
        "        # Other\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "\n",
        "        # from AIS\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'port_frac', # fraction (misnamed!) of EU-related observations at port\n",
        "        \n",
        "        ## Data quality\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'longest_jump', # longest distance between two observations\n",
        "        ],\n",
        "    'm5dd' : [ # kitchen sink, swap ME_W for Total.Propulsion\n",
        "        # Speed\n",
        "        'Speed..knots.', # Representative speed value (vague definition, see Clarkson's message)\n",
        "        \n",
        "        # Engine\n",
        "        # 'HP.Total.Propulsion', # Total ship propulsion power\n",
        "        'ME_W_ref_first', # Main engine power from WFR\n",
        "        \n",
        "        # Dimensions\n",
        "        'Draught..m.',   # Ship draught specification\n",
        "        'LBP..m.', # Length between perpendiculars\n",
        "        'LOA..m.', # Length of ship\n",
        "        'Beam.Mld..m.', # Width of ship\n",
        "        'TPC', # tonnage per centimeter (load required to increase draught)\n",
        "        # Size/capacity\n",
        "        'Size.Category', # Ship size category from WFR\n",
        "        'Dwt',\n",
        "        'NT', # Net tonnage: dimensionless index calculated from the total moulded volume of the ship's *cargo* space\n",
        "        # 'Ballast.Cap..cu.m.', # Ballast tank capacity\n",
        "        # 'Bale.Capacity..cu.m.', # Bale capacity\n",
        "\n",
        "        # Other\n",
        "        'age', # Yearly age of ship (observed year - built year)\n",
        "\n",
        "        # from AIS\n",
        "        'trip_nunique', # Number of unique EU trips detected from our AIS data\n",
        "        'port_frac', # fraction (misnamed!) of EU-related observations at port\n",
        "        \n",
        "        ## Data quality\n",
        "        'missing_frac_sea', # annual fraction of observations classified as 'sea' phase (i.e. steaming) that are interpolated (rather than observed)\n",
        "        'longest_jump', # longest distance between two observations        \n",
        "\n",
        "        ## Admiralty formula components\n",
        "        'W_component_first', # Fixed, ship-specific component of power, calculated from WFR data\n",
        "        't_m_times_v_n_sum', # sum[draught^m * speed^n], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_with_m_sum', # sum[(t/t_ref)^m], annual sum of instantaneous values from AIS data\n",
        "        't_over_t_ref_without_m_sum', # sum[(t/t_ref)], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_with_n_sum', # sum[(v/v_ref)^n], annual sum of instantaneous values from AIS data\n",
        "        'v_over_v_ref_without_n_sum', # sum[(v/v_ref)], annual sum of instantaneous values from AIS data\n",
        "        'cal_fc',\n",
        "\n",
        "        ## Distance\n",
        "        'distance_sum'\n",
        "        ],\n",
        "}\n",
        "\n",
        "ordinal_cols_dict = {\n",
        "    'm1' : ['Size.Category'],\n",
        "    'm1a' : ['Size.Category'],\n",
        "    'm1b' : ['Size.Category'],\n",
        "    'm2' : ['Size.Category'],\n",
        "    'm2a' : ['Size.Category'],\n",
        "    'm2b' : ['Size.Category'],\n",
        "    'm2c' : ['Size.Category'],\n",
        "    'm3' : ['Size.Category'],\n",
        "    'm4a' : ['Size.Category'],\n",
        "    'm4ad' : ['Size.Category'],\n",
        "    'm4b' : ['Size.Category'],\n",
        "    'm4bd' : ['Size.Category'],\n",
        "    'm4cd' : ['Size.Category'],\n",
        "    'm4dd' : ['Size.Category'],\n",
        "    'm4ed' : ['Size.Category'],\n",
        "    'm4fd' : ['Size.Category'],\n",
        "    'm4f' : ['Size.Category'],\n",
        "    'm5dd' : ['Size.Category']\n",
        "}\n",
        "\n",
        "# Define category ordering\n",
        "ordinal_encoding_cat_dict = {\n",
        "    'Size.Category' : ['Capesize', 'Panamax', 'Handymax', 'Handysize']\n",
        "}\n",
        "\n",
        "indicator_cols_dict = {\n",
        "    'm1' : [],\n",
        "    'm1a' : [],\n",
        "    'm1b' : [],\n",
        "    'm2' : [],\n",
        "    'm2a' : [],\n",
        "    'm2b' : [],\n",
        "    'm2c' : [],\n",
        "    'm3' : ['MRV.method.a', 'MRV.method.b', 'MRV.method.c', 'MRV.method.d'],\n",
        "    'm4a' : [],\n",
        "    'm4ad' : [],\n",
        "    'm4b' : [],\n",
        "    'm4bd' : [],\n",
        "    'm4cd' : [],\n",
        "    'm4dd' : [],\n",
        "    'm4ed' : [],\n",
        "    'm4fd' : [],\n",
        "    'm4f' : [],\n",
        "    'm5dd' : [],\n",
        "}\n",
        "\n",
        "cat_cols_dict = {\n",
        "    'm1' : [],\n",
        "    'm1a' : [],\n",
        "    'm1b' : [],\n",
        "    'm2' : [],\n",
        "    'm2a' : [],\n",
        "    'm2b' : [],\n",
        "    'm2c' : [],\n",
        "    'm3' : ['MRV.verifier.country', 'MRV.verifier.name'],\n",
        "    'm4a' : [],\n",
        "    'm4ad' : [],\n",
        "    'm4b' : [],\n",
        "    'm4bd' : [],\n",
        "    'm4cd' : [],\n",
        "    'm4dd' : [],\n",
        "    'm4ed' : [],\n",
        "    'm4fd' : [],\n",
        "    'm4f' : [],\n",
        "    'm5dd' : []\n",
        "}\n",
        "\n",
        "numnonneg_cols_dict = {\n",
        "    'm1' : list((set(features_dict['m1']) - set(ordinal_cols_dict['m1']) - set(indicator_cols_dict['m1']) - set(cat_cols_dict['m1']))),\n",
        "    'm1a' : list((set(features_dict['m1a']) - set(ordinal_cols_dict['m1a']) - set(indicator_cols_dict['m1a']) - set(cat_cols_dict['m1a']))),\n",
        "    'm1b' : list((set(features_dict['m1b']) - set(ordinal_cols_dict['m1b']) - set(indicator_cols_dict['m1b']) - set(cat_cols_dict['m1b']))),\n",
        "    'm2' : list((set(features_dict['m2']) - set(ordinal_cols_dict['m2']) - set(indicator_cols_dict['m2']) - set(cat_cols_dict['m2']))),\n",
        "    'm2a' : list((set(features_dict['m2a']) - set(ordinal_cols_dict['m2a']) - set(indicator_cols_dict['m2a']) - set(cat_cols_dict['m2a']))),\n",
        "    'm2b' : list((set(features_dict['m2b']) - set(ordinal_cols_dict['m2b']) - set(indicator_cols_dict['m2b']) - set(cat_cols_dict['m2b']))),\n",
        "    'm2c' : list((set(features_dict['m2c']) - set(ordinal_cols_dict['m2c']) - set(indicator_cols_dict['m2c']) - set(cat_cols_dict['m2c']))),\n",
        "    'm3' : list((set(features_dict['m3']) - set(ordinal_cols_dict['m3']) - set(indicator_cols_dict['m3']) - set(cat_cols_dict['m3']))),\n",
        "    'm4a' : list((set(features_dict['m4a']) - set(ordinal_cols_dict['m4a']) - set(indicator_cols_dict['m4a']) - set(cat_cols_dict['m4a']))),\n",
        "    'm4ad' : list((set(features_dict['m4ad']) - set(ordinal_cols_dict['m4ad']) - set(indicator_cols_dict['m4ad']) - set(cat_cols_dict['m4ad']))),\n",
        "    'm4b' : list((set(features_dict['m4b']) - set(ordinal_cols_dict['m4b']) - set(indicator_cols_dict['m4b']) - set(cat_cols_dict['m4b']))),\n",
        "    'm4bd' : list((set(features_dict['m4bd']) - set(ordinal_cols_dict['m4bd']) - set(indicator_cols_dict['m4bd']) - set(cat_cols_dict['m4bd']))),\n",
        "    'm4cd' : list((set(features_dict['m4cd']) - set(ordinal_cols_dict['m4cd']) - set(indicator_cols_dict['m4cd']) - set(cat_cols_dict['m4cd']))),\n",
        "    'm4dd' : list((set(features_dict['m4dd']) - set(ordinal_cols_dict['m4dd']) - set(indicator_cols_dict['m4dd']) - set(cat_cols_dict['m4dd']))),\n",
        "    'm4ed' : list((set(features_dict['m4ed']) - set(ordinal_cols_dict['m4ed']) - set(indicator_cols_dict['m4ed']) - set(cat_cols_dict['m4ed']))),\n",
        "    'm4fd' : list((set(features_dict['m4fd']) - set(ordinal_cols_dict['m4fd']) - set(indicator_cols_dict['m4fd']) - set(cat_cols_dict['m4fd']))),\n",
        "    'm4f' : list((set(features_dict['m4f']) - set(ordinal_cols_dict['m4f']) - set(indicator_cols_dict['m4f']) - set(cat_cols_dict['m4f']))),\n",
        "    'm5dd' : list((set(features_dict['m5dd']) - set(ordinal_cols_dict['m5dd']) - set(indicator_cols_dict['m5dd']) - set(cat_cols_dict['m5dd'])))\n",
        "}\n",
        "\n",
        "numneg_cols_dict = {\n",
        "    'm1' : [],\n",
        "    'm1a' : [],\n",
        "    'm1b' : [],\n",
        "    'm2' : [],\n",
        "    'm2a' : [],\n",
        "    'm2b' : [],\n",
        "    'm2c' : [],\n",
        "    'm3' : [],\n",
        "    'm4a' : [],\n",
        "    'm4ad' : [],\n",
        "    'm4b' : [],\n",
        "    'm4bd' : [],\n",
        "    'm4cd' : [],\n",
        "    'm4dd' : [],\n",
        "    'm4ed' : [],\n",
        "    'm4fd' : [],\n",
        "    'm4f' : [],\n",
        "    'm5dd' : []\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assign feature set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = features_dict[feature_set]\n",
        "ordinal_cols = ordinal_cols_dict[feature_set]\n",
        "indicator_cols = indicator_cols_dict[feature_set]\n",
        "cat_cols = cat_cols_dict[feature_set]\n",
        "numnonneg_cols = numnonneg_cols_dict[feature_set]\n",
        "numneg_cols = numneg_cols_dict[feature_set]\n",
        "pd.DataFrame(features, columns=['variable']).to_csv(trackeddatapath + fileprefix + 'features.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Check how many missing for each feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_frac = df_ml[features].isna().sum()/len(df_ml)\n",
        "print('Missing Fraction (if non-zero):')\n",
        "print(missing_frac[missing_frac > 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set variables for ml training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = df_ml['log_report_fc']\n",
        "X = df_ml[features + ['log_report_fc', 'log_cal_fc']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df = tribble(\n",
        "    ['model',    'class_name',                 'name',                    'type',  'scaling', 'fast'],\n",
        "     'gb',       'GradientBoostingRegressor',  'Gradient Boosting',       'tree',   False,    False,\n",
        "     'linear',   'LinearRegression',           'Linear Regression',       'linear', False,    True,\n",
        "     'lasso',    'Lasso',                      'Lasso',                   'linear', True,     True,\n",
        "     'ridge',    'Ridge',                      'Ridge',                   'linear', True,     True,\n",
        "     'rf',       'RandomForestRegressor',      'Random Forest',           'tree',   False,    False,\n",
        "     'cb',       'CatBoostRegressor',          'Cat Boost',               'tree',   False,    False\n",
        "    #  'lgbm',     'LGBMRegressor',              'Light Gradient Boosting', 'tree',   False,\n",
        "    #  'xgb',      'XGBRegressor',           'tree',   False,\n",
        ").set_index('model')\n",
        "if fast_only:\n",
        "    mdl_df = mdl_df[mdl_df['fast']]\n",
        "\n",
        "mdl_df.to_csv(trackeddatapath + fileprefix + 'mdl_settings.csv')\n",
        "mdl_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imputation, Tranformation, Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "median_imputer = SimpleImputer(strategy='median')\n",
        "missing_string = 'missing'\n",
        "impute_as_missing = SimpleImputer(strategy='constant', fill_value=missing_string)\n",
        "\n",
        "# setting categories manually is necessary for prediction in using the kfold evaluation loop\n",
        "ind_to_encode = [X[col].fillna('missing').unique() for col in indicator_cols]\n",
        "ind_encoder = OneHotEncoder(categories=ind_to_encode)\n",
        "ind_encoder_nonregularized = OneHotEncoder(categories=ind_to_encode, drop='first')\n",
        "\n",
        "cat_to_encode = [X[col].fillna('missing').unique() for col in cat_cols]\n",
        "cat_encoder = OneHotEncoder(categories=cat_to_encode)\n",
        "cat_encoder_nonregularized = OneHotEncoder(categories=cat_to_encode, drop='first')\n",
        "\n",
        "log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
        "ordinal_transformer = make_pipeline(OrdinalEncoder(categories=[values for values in ordinal_encoding_cat_dict.values()]))\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Pipelines for numerical\n",
        "impute = Pipeline(steps=[('impute', median_imputer)])\n",
        "\n",
        "impute_transform = Pipeline(steps=[\n",
        "    ('impute', median_imputer),\n",
        "    ('transform', log_transformer)])\n",
        "\n",
        "impute_scale = Pipeline(steps=[\n",
        "    ('impute', median_imputer),\n",
        "    ('scale', scaler)])\n",
        "\n",
        "impute_transform_scale = Pipeline(steps=[\n",
        "    ('impute', median_imputer),\n",
        "    ('transform', log_transformer),\n",
        "    ('scale', scaler)])\n",
        "\n",
        "# Pipelines for indicator\n",
        "ind_impute_encode = Pipeline(steps=[\n",
        "    ('impute', impute_as_missing),\n",
        "    ('encode', ind_encoder)])\n",
        "\n",
        "ind_impute_encode_nonregularized = Pipeline(steps=[\n",
        "    ('impute', impute_as_missing),\n",
        "    ('encode', ind_encoder_nonregularized)])\n",
        "\n",
        "# Pipelines for categorical\n",
        "cat_impute_encode = Pipeline(steps=[\n",
        "    ('impute', impute_as_missing),\n",
        "    ('encode', cat_encoder)])\n",
        "\n",
        "cat_impute_encode_nonregularized = Pipeline(\n",
        "    steps=[('impute', impute_as_missing),\n",
        "           ('encode', cat_encoder_nonregularized)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Column Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# scaling not required for tree-based models\n",
        "preprocessor_scaling = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('numeric_nonneg', impute_transform_scale, numnonneg_cols),\n",
        "        ('numeric_neg', impute_scale, numneg_cols),\n",
        "        ('ordinal', ordinal_transformer, ordinal_cols),\n",
        "        ('indicator', ind_impute_encode, indicator_cols),\n",
        "        ('categorical', cat_impute_encode, cat_cols)\n",
        "        ])\n",
        "\n",
        "preprocessor_noscaling = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('numeric_nonneg', impute_transform, numnonneg_cols), # or with scaling\n",
        "        ('numeric_neg', impute, numneg_cols), # or with scaling\n",
        "        ('ordinal', ordinal_transformer, ordinal_cols),\n",
        "        ('indicator', ind_impute_encode, indicator_cols),\n",
        "        ('categorical', cat_impute_encode, cat_cols)\n",
        "        ])\n",
        "\n",
        "# drops one category of onehot encoded categorical variables (only used for linreg)\n",
        "preprocessor_noscaling_drop = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('numeric_nonneg', impute_transform, numnonneg_cols), # or with scaling\n",
        "        ('numeric_neg', impute, numneg_cols), # or with scaling\n",
        "        ('ordinal', ordinal_transformer, ordinal_cols),\n",
        "        ('indicator', ind_impute_encode_nonregularized, indicator_cols),\n",
        "        ('categorical', cat_impute_encode_nonregularized, cat_cols)\n",
        "        ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Check pre-processing visually\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Plot histograms or processed variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: apply columntransformer to X and y\n",
        "# df_transformed = pd.DataFrame(mdl_gb_original[0].transform(X),\n",
        "#                               columns = features_m1)\n",
        "# # %%\n",
        "# col_to_plot = features_m1[23]\n",
        "# fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "# ax[0].hist(df_ml_train[col_to_plot])\n",
        "# ax[0].axvline(df_ml_train[col_to_plot].median(), color='black', linestyle='solid', linewidth=1, label='mean')\n",
        "# ax[0].set_title('Original')\n",
        "# ax[1].hist(df_transformed[col_to_plot])\n",
        "# ax[1].axvline(df_transformed[col_to_plot].median(), color='black', linestyle='solid', linewidth=1, label='mean')\n",
        "# ax[1].set_title('Imputed & Transformed')\n",
        "# fig.suptitle(col_to_plot)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# preprocessor_test = ColumnTransformer(\n",
        "#     transformers=[\n",
        "#         # ('indicator', ind_impute_encode, indicator_cols),\n",
        "#         # ('categorical', cat_impute_encode, cat_cols),\n",
        "#         ('indicator', ind_impute_encode_nonregularized, indicator_cols),\n",
        "#         ('categorical', cat_impute_encode_nonregularized, cat_cols)\n",
        "#         ],\n",
        "#     sparse_threshold=0)\n",
        "\n",
        "# transform_test = pd.DataFrame(\n",
        "#     preprocessor_test.fit_transform(df_ml[indicator_cols + cat_cols]),\n",
        "#     columns=preprocessor_test.get_feature_names_out())\n",
        "# transform_test.loc[:, transform_test.columns.str.contains('.a')].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_ml.loc[:, indicator_cols + cat_cols]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Base Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_base_dict = {\n",
        "    'gb': {\n",
        "        'n_estimators': 2000,\n",
        "        'learning_rate': 0.1,\n",
        "        'max_depth': 3,\n",
        "        'max_features': 'sqrt',\n",
        "        'min_samples_leaf': 20,\n",
        "        'loss': 'squared_error',\n",
        "        'min_samples_split': 20,\n",
        "        'warm_start': True\n",
        "    },\n",
        "    'linear': {},\n",
        "    'lasso': {\n",
        "        'alpha': 0.01,\n",
        "    },\n",
        "    'ridge': {\n",
        "        'alpha': 0.01,\n",
        "    },\n",
        "    'rf': {\n",
        "        'n_estimators': 200,\n",
        "        'max_depth': 10,\n",
        "        # 'max_features': 'sqrt',\n",
        "        # 'min_samples_leaf': 20,\n",
        "        # 'min_samples_split': 20,\n",
        "    },\n",
        "    'cb': {\n",
        "        'verbose': 0\n",
        "    },\n",
        "    'lgbm': {\n",
        "        'verbose': 1\n",
        "    },\n",
        "    'xgb': {} \n",
        "}\n",
        "\n",
        "\n",
        "mdl_df['base_params'] = [mdl_base_dict.get(mdl) for mdl in mdl_df.index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df['estimator'] = mdl_df.apply(lambda row: make_estimator(row['scaling'], row['class_name'], row['base_params']), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test base parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model in mdl_df.index:\n",
        "    mdl_df.loc[model, 'estimator'].fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fuel Consumption"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df['base_fc_stats'] = mdl_df.apply(\n",
        "    lambda row: calculate_stats(\n",
        "        X.log_report_fc,\n",
        "        row['estimator'].predict(X),\n",
        "        stats_dict=validation_stats),\n",
        "    axis=1)\n",
        "compare_base_fc_df = model_stats_comparison_table('base_fc_stats', 'base_params', 'estimator', mdl_df).sort_values('r2', ascending=False)\n",
        "compare_base_fc_df.to_csv(trackeddatapath + fileprefix + 'base_fc.csv')\n",
        "compare_base_fc_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df.to_pickle(datapath + fileprefix + model_df_filename + '_base.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Test base parameters complete at {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))}, after {round((time.time() - start_time)/60, 1)} minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Hyperparameter Tuning: 5-fold CV, Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df = pd.read_pickle(datapath + fileprefix + model_df_filename + '_base.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define search grids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_gs_dict = {\n",
        "    'gb': {\n",
        "        'learning_rate': [0.005, 0.01, 0.05, 0.1, 0.2],\n",
        "        'max_depth': [3, 4, 5, 6]\n",
        "    },\n",
        "    'linear': {},\n",
        "    'lasso': {\n",
        "        'alpha': [5e-3, 1e-2, 0.1, 1, 10, 100],\n",
        "    },\n",
        "    'ridge': {\n",
        "        'alpha': [5e-3, 1e-2, 0.1, 1, 10, 100, 1000, 10000, 100000],\n",
        "    },\n",
        "    'rf': {\n",
        "        'n_estimators': [200, 700, 1000],\n",
        "        'max_depth': [10, 30, 50],\n",
        "        # 'max_features': ['sqrt'],\n",
        "        # 'min_samples_leaf': [20],\n",
        "        # 'min_samples_split': [20],\n",
        "    },\n",
        "    'cb': {\n",
        "        'learning_rate' : [0.01, 0.05, 0.1],\n",
        "        'depth': [6, 8 ,10],\n",
        "        # 'iterations': [10, 50, 500],\n",
        "        'l2_leaf_reg': [1, 7, 15]\n",
        "    },\n",
        "    'lgbm': {\n",
        "        'num_leaves': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
        "        'learning_rate': [0.005, 0.01, 0.1, 0.2, 0.3],\n",
        "        'num_iterations': [10, 50, 100, 500, 1000, 5000, 10000],\n",
        "        'max_bin': [255, 300, 500, 1000],\n",
        "        'boosting' : ['gbdt', 'dart'],\n",
        "    },\n",
        "    # 'xgb': \n",
        "}\n",
        "\n",
        "\n",
        "mdl_df['gs_params'] = [mdl_gs_dict.get(mdl) for mdl in mdl_df.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for quicker testing\n",
        "# mdl_gs_dict = {\n",
        "#     'gb': {\n",
        "#         'learning_rate': [0.01],\n",
        "#         'max_depth': [3, 4]\n",
        "#     },\n",
        "#     'linear': {},\n",
        "#     'lasso': {\n",
        "#         'alpha': [0.1],\n",
        "#     },\n",
        "#     'ridge': {\n",
        "#         'alpha': [0.1],\n",
        "#     },\n",
        "#     'rf': {\n",
        "#         'n_estimators': [200],\n",
        "#         'max_depth': [10],\n",
        "#         # 'max_features': ['sqrt'],\n",
        "#         # 'min_samples_leaf': [20],\n",
        "#         # 'min_samples_split': [20],\n",
        "#     },\n",
        "#     'cb': {\n",
        "#         'depth': [6, 8],\n",
        "#         'iterations': [30],\n",
        "#         'l2_leaf_reg': [7]\n",
        "#     },\n",
        "#     'lgbm': {\n",
        "#         'num_leaves': [50],\n",
        "#         'learning_rate': [0.01, 0.1],\n",
        "#         'num_iterations': [100],\n",
        "#         'max_bin': [500],\n",
        "#         'boosting' : ['gbdt', 'dart']\n",
        "#     },\n",
        "#     # 'xgb': \n",
        "# }\n",
        "\n",
        "\n",
        "# mdl_df['gs_params'] = [mdl_gs_dict.get(mdl) for mdl in mdl_df.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add model class_name prefix to parameter names\n",
        "mdl_df['gs_params_prefix'] = mdl_df.apply(lambda row: {row['class_name'].lower() + '__' + k: v for k, v in row['gs_params'].items()}, axis=1)\n",
        "mdl_df[['gs_params', 'gs_params_prefix']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df['grid_search'] = mdl_df.apply(\n",
        "    lambda row: GridSearchCV(\n",
        "        row['estimator'],\n",
        "        row['gs_params_prefix'],\n",
        "        cv=cv_folds,\n",
        "        scoring=cv_scoring,\n",
        "        n_jobs=max_cores,\n",
        "        verbose=1),\n",
        "        axis=1)\n",
        "\n",
        "for model in mdl_df.index:\n",
        "    mdl_df.loc[model, 'grid_search'].fit(X, y)\n",
        "    \n",
        "\n",
        "mdl_df['best_estimator'] = mdl_df.apply(lambda row: row['grid_search'].best_estimator_, axis=1)\n",
        "# This estimator is refitted on whole training set\n",
        "\n",
        "# Column of best parameters chosen from grid search CV (with short names)\n",
        "mdl_df['best_params'] = mdl_df.apply(lambda row: extract_filter_params(row, 'best_estimator', 'gs_params'), axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CV Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df['best_cv_mean_score'] = mdl_df.apply(lambda row: row['grid_search'].cv_results_['mean_test_score'][row['grid_search'].best_index_], axis=1)\n",
        "\n",
        "mdl_df['best_cv_std_score'] = mdl_df.apply(lambda row: row['grid_search'].cv_results_['std_test_score'][row['grid_search'].best_index_], axis=1)\n",
        "\n",
        "cv_best_fc = (\n",
        "    mdl_df.loc[:, ['class_name', 'best_cv_mean_score', 'best_cv_std_score', 'best_params']]\n",
        "    .sort_values('best_cv_mean_score', ascending=False)\n",
        "    )\n",
        "cv_best_fc.to_csv(trackeddatapath + fileprefix + 'best_cv_fc.csv')\n",
        "cv_best_fc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Best estimator training set stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df['best_fc_stats'] = mdl_df.apply(\n",
        "    lambda row: calculate_stats(\n",
        "        X.log_report_fc,\n",
        "        row['best_estimator'].predict(X),\n",
        "        stats_dict=validation_stats),\n",
        "    axis=1)\n",
        "compare_best_fc_df = model_stats_comparison_table('best_fc_stats', 'best_params', 'best_estimator', mdl_df).sort_values('r2', ascending=False)\n",
        "compare_best_fc_df.to_csv(trackeddatapath + fileprefix + 'best_train_fc.csv')\n",
        "compare_best_fc_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df.to_pickle(datapath + fileprefix + model_df_filename + '_best.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Hyperparameter tuning complete at {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))}, after {round((time.time() - start_time)/60, 1)} minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Run time\n",
        "- takes around 25 minutes total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# processing time (seconds) of best estimators\n",
        "mdl_df.loc[:, 'grid_search'].apply(lambda x: x.cv_results_['mean_fit_time'][x.cv_results_['rank_test_score'] == 1][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation of Tuned Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df = pd.read_pickle(datapath + fileprefix + model_df_filename + '_best.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df['eval_stats'] = mdl_df.apply(\n",
        "    lambda row: cross_validate_stats(\n",
        "        X,\n",
        "        y,\n",
        "        row['best_estimator'],\n",
        "        eval_types_dict[train_eval_type],\n",
        "        validation_stats,\n",
        "        max_cores),\n",
        "    axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stats FC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eval_means_df = model_stats_comparison_table('eval_stats', 'best_params', 'best_estimator', mdl_df, 'means')\n",
        "eval_sds_df = model_stats_comparison_table('eval_stats', 'best_params', 'best_estimator', mdl_df, 'sds')\n",
        "compare_eval_df = eval_means_df.join(\n",
        "    eval_sds_df.drop(columns=['class_name', 'params']),\n",
        "    lsuffix='_mean',\n",
        "    rsuffix='_sd').sort_values('r2_mean', ascending=False)\n",
        "compare_eval_df.to_csv(trackeddatapath + fileprefix + 'eval_fc_stats.csv')\n",
        "compare_eval_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df.to_pickle(datapath + fileprefix + model_df_filename + '_eval.pkl')\n",
        "\n",
        "print(f\"Training set evaluation complete at {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))}, after {round((time.time() - start_time)/60, 1)} minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Set Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df = pd.read_pickle(datapath + fileprefix + model_df_filename + '_eval.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Stats FC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Engineering Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stats_eng = calculate_stats('log_report_fc', 'log_cal_fc', X, validation_stats)\n",
        "stats_eng_df = pd.DataFrame(stats_eng).drop('names', axis=1).T\n",
        "stats_eng_df['model'] = 'eng'\n",
        "stats_eng_df = stats_eng_df.set_index('model')\n",
        "stats_eng_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ML Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model in mdl_df.index:\n",
        "    mdl_df.loc[model, 'best_estimator'].fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df['train_prediction'] = mdl_df.apply(lambda row: row['best_estimator'].predict(X), axis=1)\n",
        "mdl_df['train_fc_stats'] = mdl_df.apply(\n",
        "    lambda row: calculate_stats(\n",
        "        X.log_report_fc,\n",
        "        row['train_prediction'],\n",
        "        stats_dict=validation_stats),\n",
        "    axis=1)\n",
        "compare_train_fc_df = model_stats_comparison_table('train_fc_stats', 'best_params', 'best_estimator', mdl_df)\n",
        "compare_train_fc_df = pd.concat([stats_eng_df, compare_train_fc_df], axis=0)\n",
        "compare_train_fc_df.sort_values('r2', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Two-way plot of FC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df.apply(lambda row: two_way_plot(X.log_report_fc, row['train_prediction'], title=row['name'], xlabel='True Fuel Consumption', ylabel='Predicted Fuel Consumption', regline=True, legend=False), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Importance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Permutation-based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df['perm_importance'] = mdl_df.apply(lambda row: permutation_importance(\n",
        "    row['best_estimator'],\n",
        "    X[features],\n",
        "    y,\n",
        "    n_repeats=10,\n",
        "    random_state=0,\n",
        "    n_jobs=max_cores),\n",
        "    axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model in mdl_df.index:\n",
        "    FI_plot(mdl_df.loc[model, 'perm_importance'], model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FI_df = pd.DataFrame()\n",
        "for model in mdl_df.index:\n",
        "    FI_df = pd.concat([FI_df, pd.DataFrame(mdl_df.loc[model, 'perm_importance']['importances_mean'], columns = ['importance'], index = features).assign(model = model)], axis=0)\n",
        "\n",
        "FI_df['rank'] = FI_df.groupby('model')['importance'].rank(ascending=False).astype(int)\n",
        "FI_df = FI_df.drop(columns='importance').pivot(columns='model', values='rank')\n",
        "FI_df['mean'] = FI_df.mean(axis=1)\n",
        "FI_df['sd'] = FI_df.std(axis=1)\n",
        "FI_df = FI_df.sort_values('mean')\n",
        "FI_df.to_csv(trackeddatapath + fileprefix + 'FI.csv')\n",
        "FI_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Evaluation complete at {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))}, after {round((time.time() - start_time)/60, 1)} minutes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Set Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load, explore, filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ml_test = pd.read_csv(readdatapath + \"df_ml_\" + tol_type + \"_test.csv\", low_memory=False)\n",
        "\n",
        "# for nicer colors when plotting\n",
        "df_ml_test = df_ml_test.sort_values('year')\n",
        "df_ml_test['year_str'] = df_ml_test['year'].astype(str) \n",
        "\n",
        "# Label as outliers according *training* set thresholds\n",
        "df_ml_test['outlier'] = ~df_ml_test['residual'].between(\n",
        "    raw_mean - outlier_threshold * raw_std,\n",
        "    raw_mean + outlier_threshold * raw_std,\n",
        "    inclusive='neither')\n",
        "\n",
        "df_ml_test.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ml_test['outlier'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot raw vs. training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "two_way_plot(\n",
        "     'log_report_fc',\n",
        "     'log_cal_fc',\n",
        "     df_ml_test,\n",
        "     hue='outlier',\n",
        "     title='Raw Test Data',\n",
        "     xlabel='log Reported Fuel Consumption',\n",
        "     ylabel='log Calculated Fuel Consumption',\n",
        "     legend_title='Outlier',\n",
        "     regline=False)\n",
        "    #  savepath=plotpath + fileprefix + 'twoway_fc_raw.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Histogram by outlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(raw_mean - outlier_threshold * raw_std)\n",
        "print(raw_mean + outlier_threshold * raw_std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(5, 5), dpi=300)\n",
        "sns.histplot(data=df_ml_test, x='residual', hue='outlier', alpha=0.5, kde=False)\n",
        "hue_values = df_ml['year'].unique()\n",
        "color_map = dict(zip(hue_values, sns.color_palette()))\n",
        "for year, color in color_map.items():\n",
        "    plt.axvline(df_ml[df_ml['year'] == year]['residual'].mean(), color=color)\n",
        "plt.title('Test Data Residual')\n",
        "plt.xlabel('Residual')\n",
        "# plt.savefig(plotpath + fileprefix + 'hist_residualbyyear_filtered_.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ml_test = df_ml_test.loc[~df_ml_test['outlier']]\n",
        "print(f'Filtered Data: \\n observations: {len(df_ml)} \\n target mean: {df_ml_test.residual.mean()} \\n target sd: {df_ml_test.residual.std()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create df of both train and test data for plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_ml_all = pd.concat([df_ml, df_ml_test], keys=['Training Set', 'Test Set'])\n",
        "df_ml_all.reset_index(level=0, inplace=True)\n",
        "df_ml_all.rename(columns={'level_0': 'set'}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot filtered vs. training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "two_way_plot(\n",
        "     'log_report_fc',\n",
        "     'log_cal_fc',\n",
        "     df_ml_all,\n",
        "     hue='set',\n",
        "     # title='Filtered Data: Test vs. Training',\n",
        "     xlabel='Log Reported Fuel Consumption',\n",
        "     ylabel='Log Calculated Fuel Consumption',\n",
        "     regline=False,\n",
        "     savepath=plotpath + fileprefix + 'twoway_fc_filtered_traintest.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot by year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "two_way_plot(\n",
        "     'log_report_fc',\n",
        "     'log_cal_fc',\n",
        "     df_ml_all,\n",
        "     hue='year_str',\n",
        "     title='Filtered Data: By Year',\n",
        "     xlabel='Log Reported Fuel Consumption',\n",
        "     ylabel='Log Calculated Fuel Consumption',\n",
        "     legend=True,\n",
        "     legend_title='Year',\n",
        "     regline=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Performance comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stats_eng_test = calculate_stats('log_report_fc', 'log_cal_fc', df_ml_test, validation_stats)\n",
        "stats_eng_test_df = pd.DataFrame(stats_eng_test).drop('names', axis=1).T\n",
        "stats_eng_test_df['model'] = 'eng'\n",
        "stats_eng_test_df = stats_eng_test_df.set_index('model')\n",
        "\n",
        "mdl_df['test_prediction'] = mdl_df.apply(lambda row: row['best_estimator'].predict(df_ml_test), axis=1)\n",
        "\n",
        "\n",
        "mdl_df['test_fc_stats'] = mdl_df.apply(\n",
        "    lambda row: calculate_stats(\n",
        "        df_ml_test.log_report_fc,\n",
        "        row['test_prediction'],\n",
        "        stats_dict=validation_stats),\n",
        "    axis=1)\n",
        "compare_test_fc_df = model_stats_comparison_table('test_fc_stats', 'best_params', 'best_estimator', mdl_df)\n",
        "compare_test_fc_df = pd.concat([stats_eng_test_df, compare_test_fc_df], axis=0).sort_values('r2', ascending=False)\n",
        "\n",
        "compare_test_fc_df.to_csv(trackeddatapath + fileprefix + 'test_fc.csv')\n",
        "print('Eng + ML')\n",
        "compare_test_fc_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mdl_df['perm_importance_test'] = mdl_df.apply(lambda row: permutation_importance(\n",
        "    row['best_estimator'],\n",
        "    df_ml_test[features],\n",
        "    df_ml_test.log_report_fc,\n",
        "    n_repeats=10,\n",
        "    random_state=0,\n",
        "    n_jobs=max_cores),\n",
        "    axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model in mdl_df.index:\n",
        "    FI_plot(mdl_df.loc[model, 'perm_importance_test'], model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FI_df = pd.DataFrame()\n",
        "for model in mdl_df.index:\n",
        "    FI_df = pd.concat([FI_df, pd.DataFrame(mdl_df.loc[model, 'perm_importance_test']['importances_mean'], columns = ['importance'], index = features).assign(model = model)], axis=0)\n",
        "\n",
        "FI_df['rank'] = FI_df.groupby('model')['importance'].rank(ascending=False).astype(int)\n",
        "FI_df = FI_df.drop(columns='importance').pivot(columns='model', values='rank')\n",
        "FI_df['mean'] = FI_df.mean(axis=1)\n",
        "FI_df['sd'] = FI_df.std(axis=1)\n",
        "FI_df = FI_df.sort_values('mean')\n",
        "FI_df.to_csv(trackeddatapath + fileprefix + 'FI_test.csv')\n",
        "FI_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Totally complete at {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))}, after {round((time.time() - start_time)/60, 1)} minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
